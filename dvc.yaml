# DVC Pipeline for Document Classifier
# Run with: dvc repro

stages:
  # Stage 1: Extract text from PDFs using OCR
  extract_text:
    cmd: python main.py extract
    deps:
    - data/dataset/
    - src/ocr.py
    - src/trainer.py
    - config.py
    outs:
    - data/dataset_raw.pkl
    - data/dataset_raw.csv

  # Stage 2: Preprocess/Normalize extracted text
  preprocess:
    cmd: python main.py preprocess
    deps:
    - data/dataset_raw.pkl
    - src/normalizer.py
    - src/trainer.py
    - config.py
    outs:
    - data/dataset_clean.pkl
    - data/dataset_clean.csv

  # Stage 3: Train the model
  train:
    cmd: python main.py train-model
    deps:
    - data/dataset_clean.pkl
    - src/trainer.py
    - config.py
    outs:
    - models/svm_model.joblib
    - models/tfidf_vectorizer.joblib
    - models/model_metadata.json

  # Stage 4: Evaluate the model
  evaluate:
    cmd: >
      python -c "
      import json;
      from pathlib import Path;
      metadata = json.loads(Path('models/model_metadata.json').read_text());
      print('Model Evaluation Results');
      print('  Test Accuracy:', round(metadata['test_accuracy'], 4));
      print('  Test F1 Macro:', round(metadata['test_f1_macro'], 4));
      print('  Classes:', metadata['classes']);
      print('  Samples: train=%d, val=%d, test=%d' % (metadata['n_train'], metadata['n_val'],
      metadata['n_test']));
      if metadata['test_accuracy'] < 0.90:
        print('WARNING: Model accuracy below 90%!');
        exit(1)
      "
    deps:
    - models/model_metadata.json
    - models/svm_model.joblib

# Note: Parameters are defined in config.py
# To track experiments, use: dvc exp run
